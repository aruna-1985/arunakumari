{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Copy of Cyclegan.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yZdfQvwfn_II",
        "6oxbRqPuyVpp",
        "3zr4OBnQzcCs",
        "dujDxdyl76-1",
        "_WEAIh3KzerJ",
        "6HJ80i93yY2J",
        "LtxavWLnybl1"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aruna20200/arunakumari/blob/master/Copy_of_Cyclegan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jbwk3FVpK9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce09a30-a3d8-40ee-8587-41ab3d159760"
      },
      "source": [
        "!git clone https://github.com/fastai/fastai.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fastai'...\n",
            "remote: Enumerating objects: 13972, done.\u001b[K\n",
            "remote: Counting objects: 100% (173/173), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 13972 (delta 83), reused 113 (delta 50), pack-reused 13799\u001b[K\n",
            "Receiving objects: 100% (13972/13972), 640.08 MiB | 21.98 MiB/s, done.\n",
            "Resolving deltas: 100% (10934/10934), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZdfQvwfn_II"
      },
      "source": [
        "# 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCp8VfuQqdAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4ab505-353b-4af5-dd71-ad004684fdf2"
      },
      "source": [
        "cd /content/fastai/courses/dl2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/fastai/courses/dl2'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Wy2Defved7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4104f2cf-624c-4d7f-f09e-23b13a499f3b"
      },
      "source": [
        "!wget https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-29 05:30:15--  https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip\n",
            "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.244.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116867962 (111M) [application/zip]\n",
            "Saving to: ‘horse2zebra.zip’\n",
            "\n",
            "horse2zebra.zip     100%[===================>] 111.45M  4.35MB/s    in 28s     \n",
            "\n",
            "2021-04-29 05:30:43 (4.00 MB/s) - ‘horse2zebra.zip’ saved [116867962/116867962]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGBpbF-pHDD8",
        "outputId": "6bdedc4b-2841-4866-af22-f461278bcd2d"
      },
      "source": [
        "!pip install matplotlib-venn"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.7/dist-packages (0.11.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from matplotlib-venn) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from matplotlib-venn) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from matplotlib-venn) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->matplotlib-venn) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->matplotlib-venn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->matplotlib-venn) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->matplotlib-venn) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->matplotlib-venn) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_uQZ9mLHGey",
        "outputId": "3549342a-0432-4801-e481-1396016071bf"
      },
      "source": [
        "!apt-get -qq install -y libfluidsynth1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libfluidsynth1:amd64.\n",
            "(Reading database ... 160690 files and directories currently installed.)\n",
            "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
            "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMSrV4bkHMji"
      },
      "source": [
        "Install 7zip reader libarchive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amDs8q66HLOO",
        "outputId": "b5b5a3f0-2678-481c-cf4f-7d2516c0d406"
      },
      "source": [
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 160695 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.2.2-3.1ubuntu0.6_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.2.2-3.1ubuntu0.6) ...\n",
            "Setting up libarchive-dev:amd64 (3.2.2-3.1ubuntu0.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting libarchive\n",
            "  Downloading https://files.pythonhosted.org/packages/bf/d4/26f5c9835d4d648e4f22b5fb91288457698e928aaf9d4ab7eff405b7ef03/libarchive-0.4.7.tar.gz\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 12.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: libarchive\n",
            "  Building wheel for libarchive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libarchive: filename=libarchive-0.4.7-cp37-none-any.whl size=31633 sha256=06407b465073b33444b53f29c350f8465a38f6e95e320f1b301f1bf517d8f48a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/5c/fa/92ee330d259e8fa5bedbd53f67040710fe81cfa463b8711d26\n",
            "Successfully built libarchive\n",
            "Installing collected packages: nose, libarchive\n",
            "Successfully installed libarchive-0.4.7 nose-1.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PG6QuGuHZD7"
      },
      "source": [
        "Install GraphViz & PyDot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQmfB-YEHXnJ",
        "outputId": "43cc0ada-49d5-48d3-ac65-2f074186ebd7"
      },
      "source": [
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3n6k_FlHeuq"
      },
      "source": [
        "Install cartopy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tjwmKx8HUQJ"
      },
      "source": [
        "!pip install cartopy\n",
        "import cartopy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYirb5-7us-G"
      },
      "source": [
        "!unzip -q -n horse2zebra.zip"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HLYPqZxIw2M",
        "outputId": "9599ddc8-adbe-4d3d-e730-d03110a3376f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install cyclegan"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cyclegan (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for cyclegan\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvF4JMYXn_In",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "2eae2c51-7e87-4f2d-b117-da3b97b0da9d"
      },
      "source": [
        "from cgan.options.train_options import TrainOptions\n",
        "from cgan.data.data_loader import CreateDataLoader"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-640c3ea516e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_options\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainOptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCreateDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cgan'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u17xmZ5IvwP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhvHUm31_7AV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "596c8f1f-a9ef-48f2-ea2c-161a9311c378"
      },
      "source": [
        "opt = TrainOptions().parse(['--dataroot', 'horse2zebra', '--nThreads', '8', '--no_dropout',\n",
        "                           '--niter', '100', '--niter_decay', '100', '--name', 'nodrop', '--gpu_ids', '0'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bdaf9e7d4449>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m opt = TrainOptions().parse(['--dataroot', 'horse2zebra', '--nThreads', '8', '--no_dropout',\n\u001b[0m\u001b[1;32m      2\u001b[0m                            '--niter', '100', '--niter_decay', '100', '--name', 'nodrop', '--gpu_ids', '0'])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TrainOptions' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq8AdTLFn_Iu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "c9757550-9b3e-475f-b6f2-93bc4b6410d9"
      },
      "source": [
        "data_loader = CreateDataLoader(opt)\n",
        "dataset = data_loader.load_data()\n",
        "dataset_size = len(data_loader)\n",
        "dataset_size"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1f6ebcbcf15e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCreateDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CreateDataLoader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oxbRqPuyVpp"
      },
      "source": [
        "# 2. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48-ONrelzl7h"
      },
      "source": [
        "import torch\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Variable\n",
        "import itertools\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuTuMPnO7sb8"
      },
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import functools\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P54V2nid8Dgk"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zr4OBnQzcCs"
      },
      "source": [
        "## 2.1 Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odm2COBqzUe6"
      },
      "source": [
        "class BaseModel():\n",
        "    def name(self): return 'BaseModel'\n",
        "\n",
        "    def initialize(self, opt):\n",
        "        self.opt = opt\n",
        "        self.gpu_ids = opt.gpu_ids\n",
        "        self.isTrain = opt.isTrain\n",
        "        self.Tensor = torch.cuda.FloatTensor if self.gpu_ids else torch.Tensor\n",
        "        self.save_dir = os.path.join(opt.checkpoints_dir, opt.name)\n",
        "\n",
        "    def set_input(self, input): self.input = input\n",
        "    def forward(self): pass\n",
        "    def test(self): pass\n",
        "    def get_image_paths(self): pass\n",
        "    def optimize_parameters(self): pass\n",
        "    def get_current_visuals(self): return self.input\n",
        "    def get_current_errors(self): return {}\n",
        "    def save(self, label): pass\n",
        "\n",
        "    # helper saving function that can be used by subclasses\n",
        "    def save_network(self, network, network_label, epoch_label, gpu_ids):\n",
        "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
        "        save_path = os.path.join(self.save_dir, save_filename)\n",
        "        torch.save(network.cpu().state_dict(), save_path)\n",
        "        if len(gpu_ids) and torch.cuda.is_available(): network.cuda(gpu_ids[0])\n",
        "\n",
        "    # helper loading function that can be used by subclasses\n",
        "    def load_network(self, network, network_label, epoch_label):\n",
        "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
        "        save_path = os.path.join(self.save_dir, save_filename)\n",
        "        network.load_state_dict(torch.load(save_path))\n",
        "\n",
        "    # update learning rate (called once every epoch)\n",
        "    def update_learning_rate(self):\n",
        "        for scheduler in self.schedulers: scheduler.step()\n",
        "        lr = self.optimizers[0].param_groups[0]['lr']\n",
        "        print('learning rate = %.7f' % lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VGt-PEW7CJs"
      },
      "source": [
        "## 2.2 Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zd_fEVx7G32"
      },
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    # print(classname)\n",
        "    if classname.find('Conv') != -1:\n",
        "        init.normal(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        init.normal(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        init.normal(m.weight.data, 1.0, 0.02)\n",
        "        init.constant(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "def init_weights(net, init_type='normal'):\n",
        "    print('initialization method [%s]' % init_type)\n",
        "    if init_type == 'normal':\n",
        "        net.apply(weights_init_normal)\n",
        "    else:\n",
        "        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
        "\n",
        "\n",
        "def get_norm_layer(norm_type='instance'):\n",
        "    if norm_type == 'batch':\n",
        "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True)\n",
        "    elif norm_type == 'instance':\n",
        "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False)\n",
        "    elif norm_type == 'none':\n",
        "        norm_layer = None\n",
        "    else:\n",
        "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
        "    return norm_layer\n",
        "\n",
        "\n",
        "def get_scheduler(optimizer, opt):\n",
        "    if opt.lr_policy == 'lambda':\n",
        "        def lambda_rule(epoch):\n",
        "            lr_l = 1.0 - max(0, epoch + 1 + opt.epoch_count - opt.niter) / float(opt.niter_decay + 1)\n",
        "            return lr_l\n",
        "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
        "    elif opt.lr_policy == 'step':\n",
        "        scheduler = lr_scheduler.StepLR(optimizer, step_size=opt.lr_decay_iters, gamma=0.1)\n",
        "    elif opt.lr_policy == 'plateau':\n",
        "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
        "    else:\n",
        "        return NotImplementedError('learning rate policy [%s] is not implemented', opt.lr_policy)\n",
        "    return scheduler\n",
        "\n",
        "\n",
        "def define_G(input_nc, output_nc, ngf, which_model_netG, norm='batch', use_dropout=False, init_type='normal', gpu_ids=[]):\n",
        "    netG = None\n",
        "    use_gpu = len(gpu_ids) > 0\n",
        "    norm_layer = get_norm_layer(norm_type=norm)\n",
        "\n",
        "    if use_gpu:\n",
        "        assert(torch.cuda.is_available())\n",
        "\n",
        "    if which_model_netG == 'resnet_9blocks':\n",
        "        netG = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=9, gpu_ids=gpu_ids)\n",
        "    else:\n",
        "        raise NotImplementedError('Generator model name [%s] is not recognized' % which_model_netG)\n",
        "    if len(gpu_ids) > 0:\n",
        "        netG.cuda(gpu_ids[0])\n",
        "    init_weights(netG, init_type=init_type)\n",
        "    return netG\n",
        "\n",
        "\n",
        "def define_D(input_nc, ndf, which_model_netD,\n",
        "             n_layers_D=3, norm='batch', use_sigmoid=False, init_type='normal', gpu_ids=[]):\n",
        "    netD = None\n",
        "    use_gpu = len(gpu_ids) > 0\n",
        "    norm_layer = get_norm_layer(norm_type=norm)\n",
        "\n",
        "    if use_gpu:\n",
        "        assert(torch.cuda.is_available())\n",
        "    if which_model_netD == 'basic':\n",
        "        netD = NLayerDiscriminator(input_nc, ndf, n_layers=3, norm_layer=norm_layer, use_sigmoid=use_sigmoid, gpu_ids=gpu_ids)\n",
        "    else:\n",
        "        raise NotImplementedError('Discriminator model name [%s] is not recognized' %\n",
        "                                  which_model_netD)\n",
        "    if use_gpu:\n",
        "        netD.cuda(gpu_ids[0])\n",
        "    init_weights(netD, init_type=init_type)\n",
        "    return netD\n",
        "\n",
        "\n",
        "def print_network(net):\n",
        "    num_params = 0\n",
        "    for param in net.parameters():\n",
        "        num_params += param.numel()\n",
        "    print(net)\n",
        "    print('Total number of parameters: %d' % num_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDqtLWdo7G6t"
      },
      "source": [
        "##############################################################################\n",
        "# Classes\n",
        "##############################################################################\n",
        "\n",
        "\n",
        "# Defines the GAN loss which uses either LSGAN or the regular GAN.\n",
        "# When LSGAN is used, it is basically same as MSELoss,\n",
        "# but it abstracts away the need to create the target label tensor\n",
        "# that has the same size as the input\n",
        "class GANLoss(nn.Module):\n",
        "    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0,\n",
        "                 tensor=torch.FloatTensor):\n",
        "        super(GANLoss, self).__init__()\n",
        "        self.real_label = target_real_label\n",
        "        self.fake_label = target_fake_label\n",
        "        self.real_label_var = None\n",
        "        self.fake_label_var = None\n",
        "        self.Tensor = tensor\n",
        "        if use_lsgan:\n",
        "            self.loss = nn.MSELoss()\n",
        "        else:\n",
        "            self.loss = nn.BCELoss()\n",
        "\n",
        "    def get_target_tensor(self, input, target_is_real):\n",
        "        target_tensor = None\n",
        "        if target_is_real:\n",
        "            create_label = ((self.real_label_var is None) or\n",
        "                            (self.real_label_var.numel() != input.numel()))\n",
        "            if create_label:\n",
        "                real_tensor = self.Tensor(input.size()).fill_(self.real_label)\n",
        "                self.real_label_var = Variable(real_tensor, requires_grad=False)\n",
        "            target_tensor = self.real_label_var\n",
        "        else:\n",
        "            create_label = ((self.fake_label_var is None) or\n",
        "                            (self.fake_label_var.numel() != input.numel()))\n",
        "            if create_label:\n",
        "                fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n",
        "                self.fake_label_var = Variable(fake_tensor, requires_grad=False)\n",
        "            target_tensor = self.fake_label_var\n",
        "        return target_tensor\n",
        "\n",
        "    def __call__(self, input, target_is_real):\n",
        "        target_tensor = self.get_target_tensor(input, target_is_real)\n",
        "        return self.loss(input, target_tensor)\n",
        "\n",
        "\n",
        "# Defines the generator that consists of Resnet blocks between a few\n",
        "# downsampling/upsampling operations.\n",
        "# Code and idea originally from Justin Johnson's architecture.\n",
        "# https://github.com/jcjohnson/fast-neural-style/\n",
        "class ResnetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, gpu_ids=[], padding_type='reflect'):\n",
        "        assert(n_blocks >= 0)\n",
        "        super(ResnetGenerator, self).__init__()\n",
        "        self.input_nc = input_nc\n",
        "        self.output_nc = output_nc\n",
        "        self.ngf = ngf\n",
        "        self.gpu_ids = gpu_ids\n",
        "        if type(norm_layer) == functools.partial:\n",
        "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "        else:\n",
        "            use_bias = norm_layer == nn.InstanceNorm2d\n",
        "\n",
        "        model = [nn.ReflectionPad2d(3),\n",
        "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0,\n",
        "                           bias=use_bias),\n",
        "                 norm_layer(ngf),\n",
        "                 nn.ReLU(True)]\n",
        "\n",
        "        n_downsampling = 2\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2**i\n",
        "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3,\n",
        "                                stride=2, padding=1, bias=use_bias),\n",
        "                      norm_layer(ngf * mult * 2),\n",
        "                      nn.ReLU(True)]\n",
        "\n",
        "        mult = 2**n_downsampling\n",
        "        for i in range(n_blocks):\n",
        "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
        "\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2**(n_downsampling - i)\n",
        "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
        "                                         kernel_size=3, stride=2,\n",
        "                                         padding=1, output_padding=1,\n",
        "                                         bias=use_bias),\n",
        "                      norm_layer(int(ngf * mult / 2)),\n",
        "                      nn.ReLU(True)]\n",
        "        model += [nn.ReflectionPad2d(3)]\n",
        "        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
        "        model += [nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, input):\n",
        "        if self.gpu_ids and isinstance(input.data, torch.cuda.FloatTensor):\n",
        "            return nn.parallel.data_parallel(self.model, input, self.gpu_ids)\n",
        "        else:\n",
        "            return self.model(input)\n",
        "\n",
        "\n",
        "# Define a resnet block\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
        "\n",
        "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
        "        conv_block = []\n",
        "        p = 0\n",
        "        if padding_type == 'reflect':\n",
        "            conv_block += [nn.ReflectionPad2d(1)]\n",
        "        elif padding_type == 'replicate':\n",
        "            conv_block += [nn.ReplicationPad2d(1)]\n",
        "        elif padding_type == 'zero':\n",
        "            p = 1\n",
        "        else:\n",
        "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
        "\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
        "                       norm_layer(dim),\n",
        "                       nn.ReLU(True)]\n",
        "        if use_dropout:\n",
        "            conv_block += [nn.Dropout(0.5)]\n",
        "\n",
        "        p = 0\n",
        "        if padding_type == 'reflect':\n",
        "            conv_block += [nn.ReflectionPad2d(1)]\n",
        "        elif padding_type == 'replicate':\n",
        "            conv_block += [nn.ReplicationPad2d(1)]\n",
        "        elif padding_type == 'zero':\n",
        "            p = 1\n",
        "        else:\n",
        "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
        "                       norm_layer(dim)]\n",
        "\n",
        "        return nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x + self.conv_block(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "# Defines the PatchGAN discriminator with the specified arguments.\n",
        "class NLayerDiscriminator(nn.Module):\n",
        "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, use_sigmoid=False, gpu_ids=[]):\n",
        "        super(NLayerDiscriminator, self).__init__()\n",
        "        self.gpu_ids = gpu_ids\n",
        "        if type(norm_layer) == functools.partial:\n",
        "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "        else:\n",
        "            use_bias = norm_layer == nn.InstanceNorm2d\n",
        "\n",
        "        kw = 4\n",
        "        padw = 1\n",
        "        sequence = [\n",
        "            nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "\n",
        "        nf_mult = 1\n",
        "        nf_mult_prev = 1\n",
        "        for n in range(1, n_layers):\n",
        "            nf_mult_prev = nf_mult\n",
        "            nf_mult = min(2**n, 8)\n",
        "            sequence += [\n",
        "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
        "                          kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
        "                norm_layer(ndf * nf_mult),\n",
        "                nn.LeakyReLU(0.2, True)\n",
        "            ]\n",
        "\n",
        "        nf_mult_prev = nf_mult\n",
        "        nf_mult = min(2**n_layers, 8)\n",
        "        sequence += [\n",
        "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
        "                      kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
        "            norm_layer(ndf * nf_mult),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "\n",
        "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]\n",
        "\n",
        "        if use_sigmoid:\n",
        "            sequence += [nn.Sigmoid()]\n",
        "\n",
        "        self.model = nn.Sequential(*sequence)\n",
        "\n",
        "    def forward(self, input):\n",
        "        if len(self.gpu_ids) and isinstance(input.data, torch.cuda.FloatTensor):\n",
        "            return nn.parallel.data_parallel(self.model, input, self.gpu_ids)\n",
        "        else:\n",
        "            return self.model(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dujDxdyl76-1"
      },
      "source": [
        "## 2.3 Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBBpo8FV79mO"
      },
      "source": [
        "# Converts a Tensor into a Numpy array\n",
        "# |imtype|: the desired type of the converted numpy array\n",
        "def tensor2im(image_tensor, imtype=np.uint8):\n",
        "    image_numpy = image_tensor[0].cpu().float().numpy()\n",
        "    if image_numpy.shape[0] == 1:\n",
        "        image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
        "    image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
        "    return image_numpy.astype(imtype)\n",
        "\n",
        "\n",
        "def diagnose_network(net, name='network'):\n",
        "    mean = 0.0\n",
        "    count = 0\n",
        "    for param in net.parameters():\n",
        "        if param.grad is not None:\n",
        "            mean += torch.mean(torch.abs(param.grad.data))\n",
        "            count += 1\n",
        "    if count > 0:\n",
        "        mean = mean / count\n",
        "    print(name)\n",
        "    print(mean)\n",
        "\n",
        "\n",
        "def save_image(image_numpy, image_path):\n",
        "    image_pil = Image.fromarray(image_numpy)\n",
        "    image_pil.save(image_path)\n",
        "\n",
        "\n",
        "def print_numpy(x, val=True, shp=False):\n",
        "    x = x.astype(np.float64)\n",
        "    if shp:\n",
        "        print('shape,', x.shape)\n",
        "    if val:\n",
        "        x = x.flatten()\n",
        "        print('mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f' % (\n",
        "            np.mean(x), np.min(x), np.max(x), np.median(x), np.std(x)))\n",
        "\n",
        "\n",
        "def mkdirs(paths):\n",
        "    if isinstance(paths, list) and not isinstance(paths, str):\n",
        "        for path in paths:\n",
        "            mkdir(path)\n",
        "    else:\n",
        "        mkdir(paths)\n",
        "\n",
        "\n",
        "def mkdir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvukNsat8Ng-"
      },
      "source": [
        "class ImagePool():\n",
        "    def __init__(self, pool_size):\n",
        "        self.pool_size = pool_size\n",
        "        if self.pool_size > 0:\n",
        "            self.num_imgs = 0\n",
        "            self.images = []\n",
        "\n",
        "    def query(self, images):\n",
        "        if self.pool_size == 0:\n",
        "            return Variable(images)\n",
        "        return_images = []\n",
        "        for image in images:\n",
        "            image = torch.unsqueeze(image, 0)\n",
        "            if self.num_imgs < self.pool_size:\n",
        "                self.num_imgs = self.num_imgs + 1\n",
        "                self.images.append(image)\n",
        "                return_images.append(image)\n",
        "            else:\n",
        "                p = random.uniform(0, 1)\n",
        "                if p > 0.5:\n",
        "                    random_id = random.randint(0, self.pool_size - 1)\n",
        "                    tmp = self.images[random_id].clone()\n",
        "                    self.images[random_id] = image\n",
        "                    return_images.append(tmp)\n",
        "                else:\n",
        "                    return_images.append(image)\n",
        "        return_images = Variable(torch.cat(return_images, 0))\n",
        "        return return_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WEAIh3KzerJ"
      },
      "source": [
        "## 2.4 Cycle GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8_d7pl-zUhM"
      },
      "source": [
        "class CycleGANModel(BaseModel):\n",
        "    def name(self):\n",
        "        return 'CycleGANModel'\n",
        "\n",
        "    def initialize(self, opt):\n",
        "        BaseModel.initialize(self, opt)\n",
        "        # load/define networks\n",
        "        # The naming conversion is different from those used in the paper\n",
        "        # Code (paper): G_A (G), G_B (F), D_A (D_Y), D_B (D_X)\n",
        "\n",
        "        self.netG_A = define_G(opt.input_nc, opt.output_nc,\n",
        "                                        opt.ngf, opt.which_model_netG, opt.norm, not opt.no_dropout, opt.init_type, self.gpu_ids)\n",
        "        self.netG_B = define_G(opt.output_nc, opt.input_nc,\n",
        "                                        opt.ngf, opt.which_model_netG, opt.norm, not opt.no_dropout, opt.init_type, self.gpu_ids)\n",
        "\n",
        "        if self.isTrain:\n",
        "            use_sigmoid = opt.no_lsgan\n",
        "            self.netD_A = define_D(opt.output_nc, opt.ndf,\n",
        "                                            opt.which_model_netD,\n",
        "                                            opt.n_layers_D, opt.norm, use_sigmoid, opt.init_type, self.gpu_ids)\n",
        "            self.netD_B = define_D(opt.input_nc, opt.ndf,\n",
        "                                            opt.which_model_netD,\n",
        "                                            opt.n_layers_D, opt.norm, use_sigmoid, opt.init_type, self.gpu_ids)\n",
        "        if not self.isTrain or opt.continue_train:\n",
        "            which_epoch = opt.which_epoch\n",
        "            self.load_network(self.netG_A, 'G_A', which_epoch)\n",
        "            self.load_network(self.netG_B, 'G_B', which_epoch)\n",
        "            if self.isTrain:\n",
        "                self.load_network(self.netD_A, 'D_A', which_epoch)\n",
        "                self.load_network(self.netD_B, 'D_B', which_epoch)\n",
        "\n",
        "        if self.isTrain:\n",
        "            self.fake_A_pool = ImagePool(opt.pool_size)\n",
        "            self.fake_B_pool = ImagePool(opt.pool_size)\n",
        "            # define loss functions\n",
        "            self.criterionGAN = GANLoss(use_lsgan=not opt.no_lsgan, tensor=self.Tensor)\n",
        "            self.criterionCycle = torch.nn.L1Loss()\n",
        "            self.criterionIdt = torch.nn.L1Loss()\n",
        "            # initialize optimizers\n",
        "            self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()),\n",
        "                                                lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "            self.optimizer_D_A = torch.optim.Adam(self.netD_A.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "            self.optimizer_D_B = torch.optim.Adam(self.netD_B.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "            self.optimizers = []\n",
        "            self.schedulers = []\n",
        "            self.optimizers.append(self.optimizer_G)\n",
        "            self.optimizers.append(self.optimizer_D_A)\n",
        "            self.optimizers.append(self.optimizer_D_B)\n",
        "            for optimizer in self.optimizers:\n",
        "                self.schedulers.append(get_scheduler(optimizer, opt))\n",
        "\n",
        "        print('---------- Networks initialized -------------')\n",
        "        print_network(self.netG_A)\n",
        "        print_network(self.netG_B)\n",
        "        if self.isTrain:\n",
        "            print_network(self.netD_A)\n",
        "            print_network(self.netD_B)\n",
        "        print('-----------------------------------------------')\n",
        "\n",
        "    def set_input(self, input):\n",
        "        AtoB = self.opt.which_direction == 'AtoB'\n",
        "        input_A = input['A' if AtoB else 'B']\n",
        "        input_B = input['B' if AtoB else 'A']\n",
        "        if len(self.gpu_ids) > 0:\n",
        "            input_A = input_A.cuda(self.gpu_ids[0], async=True)\n",
        "            input_B = input_B.cuda(self.gpu_ids[0], async=True)\n",
        "        self.input_A = input_A\n",
        "        self.input_B = input_B\n",
        "        self.image_paths = input['A_paths' if AtoB else 'B_paths']\n",
        "\n",
        "    def forward(self):\n",
        "        self.real_A = Variable(self.input_A)\n",
        "        self.real_B = Variable(self.input_B)\n",
        "\n",
        "    def test(self):\n",
        "        real_A = Variable(self.input_A, volatile=True)\n",
        "        fake_B = self.netG_A(real_A)\n",
        "        self.rec_A = self.netG_B(fake_B).data\n",
        "        self.fake_B = fake_B.data\n",
        "\n",
        "        real_B = Variable(self.input_B, volatile=True)\n",
        "        fake_A = self.netG_B(real_B)\n",
        "        self.rec_B = self.netG_A(fake_A).data\n",
        "        self.fake_A = fake_A.data\n",
        "\n",
        "    # get image paths\n",
        "    def get_image_paths(self):\n",
        "        return self.image_paths\n",
        "\n",
        "    def backward_D_basic(self, netD, real, fake):\n",
        "        # Real\n",
        "        pred_real = netD(real)\n",
        "        loss_D_real = self.criterionGAN(pred_real, True)\n",
        "        # Fake\n",
        "        pred_fake = netD(fake.detach())\n",
        "        loss_D_fake = self.criterionGAN(pred_fake, False)\n",
        "        # Combined loss\n",
        "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
        "        # backward\n",
        "        loss_D.backward()\n",
        "        return loss_D\n",
        "\n",
        "    def backward_D_A(self):\n",
        "        fake_B = self.fake_B_pool.query(self.fake_B)\n",
        "        loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n",
        "        self.loss_D_A = loss_D_A.item()\n",
        "\n",
        "    def backward_D_B(self):\n",
        "        fake_A = self.fake_A_pool.query(self.fake_A)\n",
        "        loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n",
        "        self.loss_D_B = loss_D_B.item()\n",
        "\n",
        "    def backward_G(self):\n",
        "        lambda_idt = self.opt.lambda_identity\n",
        "        lambda_A = self.opt.lambda_A\n",
        "        lambda_B = self.opt.lambda_B\n",
        "        # Identity loss\n",
        "        if lambda_idt > 0:\n",
        "            # G_A should be identity if real_B is fed.\n",
        "            idt_A = self.netG_A(self.real_B)\n",
        "            loss_idt_A = self.criterionIdt(idt_A, self.real_B) * lambda_B * lambda_idt\n",
        "            # G_B should be identity if real_A is fed.\n",
        "            idt_B = self.netG_B(self.real_A)\n",
        "            loss_idt_B = self.criterionIdt(idt_B, self.real_A) * lambda_A * lambda_idt\n",
        "\n",
        "            self.idt_A = idt_A.data\n",
        "            self.idt_B = idt_B.data\n",
        "            self.loss_idt_A = loss_idt_A.item()\n",
        "            self.loss_idt_B = loss_idt_B.item()\n",
        "        else:\n",
        "            loss_idt_A = 0\n",
        "            loss_idt_B = 0\n",
        "            self.loss_idt_A = 0\n",
        "            self.loss_idt_B = 0\n",
        "\n",
        "        # GAN loss D_A(G_A(A))\n",
        "        fake_B = self.netG_A(self.real_A)\n",
        "        pred_fake = self.netD_A(fake_B)\n",
        "        loss_G_A = self.criterionGAN(pred_fake, True)\n",
        "\n",
        "        # GAN loss D_B(G_B(B))\n",
        "        fake_A = self.netG_B(self.real_B)\n",
        "        pred_fake = self.netD_B(fake_A)\n",
        "        loss_G_B = self.criterionGAN(pred_fake, True)\n",
        "\n",
        "        # Forward cycle loss\n",
        "        rec_A = self.netG_B(fake_B)\n",
        "        loss_cycle_A = self.criterionCycle(rec_A, self.real_A) * lambda_A\n",
        "\n",
        "        # Backward cycle loss\n",
        "        rec_B = self.netG_A(fake_A)\n",
        "        loss_cycle_B = self.criterionCycle(rec_B, self.real_B) * lambda_B\n",
        "        # combined loss\n",
        "        loss_G = loss_G_A + loss_G_B + loss_cycle_A + loss_cycle_B + loss_idt_A + loss_idt_B\n",
        "        loss_G.backward()\n",
        "\n",
        "        self.fake_B = fake_B.data\n",
        "        self.fake_A = fake_A.data\n",
        "        self.rec_A = rec_A.data\n",
        "        self.rec_B = rec_B.data\n",
        "\n",
        "        self.loss_G_A = loss_G_A.item()\n",
        "        self.loss_G_B = loss_G_B.item()\n",
        "        self.loss_cycle_A = loss_cycle_A.item()\n",
        "        self.loss_cycle_B = loss_cycle_B.item()\n",
        "\n",
        "    def optimize_parameters(self):\n",
        "        # forward\n",
        "        self.forward()\n",
        "        # G_A and G_B\n",
        "        self.optimizer_G.zero_grad()\n",
        "        self.backward_G()\n",
        "        self.optimizer_G.step()\n",
        "        # D_A\n",
        "        self.optimizer_D_A.zero_grad()\n",
        "        self.backward_D_A()\n",
        "        self.optimizer_D_A.step()\n",
        "        # D_B\n",
        "        self.optimizer_D_B.zero_grad()\n",
        "        self.backward_D_B()\n",
        "        self.optimizer_D_B.step()\n",
        "\n",
        "    def get_current_errors(self):\n",
        "        ret_errors = OrderedDict([('D_A', self.loss_D_A), ('G_A', self.loss_G_A), ('Cyc_A', self.loss_cycle_A),\n",
        "                                  ('D_B', self.loss_D_B), ('G_B', self.loss_G_B), ('Cyc_B', self.loss_cycle_B)])\n",
        "        if self.opt.lambda_identity > 0.0:\n",
        "            ret_errors['idt_A'] = self.loss_idt_A\n",
        "            ret_errors['idt_B'] = self.loss_idt_B\n",
        "        return ret_errors\n",
        "\n",
        "    def get_current_visuals(self):\n",
        "        real_A = tensor2im(self.input_A)\n",
        "        fake_B = tensor2im(self.fake_B)\n",
        "        rec_A = tensor2im(self.rec_A)\n",
        "        real_B = tensor2im(self.input_B)\n",
        "        fake_A = tensor2im(self.fake_A)\n",
        "        rec_B = tensor2im(self.rec_B)\n",
        "        ret_visuals = OrderedDict([('real_A', real_A), ('fake_B', fake_B), ('rec_A', rec_A),\n",
        "                                   ('real_B', real_B), ('fake_A', fake_A), ('rec_B', rec_B)])\n",
        "        if self.opt.isTrain and self.opt.lambda_identity > 0.0:\n",
        "            ret_visuals['idt_A'] = tensor2im(self.idt_A)\n",
        "            ret_visuals['idt_B'] = tensor2im(self.idt_B)\n",
        "        return ret_visuals\n",
        "\n",
        "    def save(self, label):\n",
        "        self.save_network(self.netG_A, 'G_A', label, self.gpu_ids)\n",
        "        self.save_network(self.netD_A, 'D_A', label, self.gpu_ids)\n",
        "        self.save_network(self.netG_B, 'G_B', label, self.gpu_ids)\n",
        "        self.save_network(self.netD_B, 'D_B', label, self.gpu_ids)\n",
        "\n",
        "    def load(self, label):\n",
        "        self.load_network(self.netG_A, 'G_A', label)\n",
        "        self.load_network(self.netD_A, 'D_A', label)\n",
        "        self.load_network(self.netG_B, 'G_B', label)\n",
        "        self.load_network(self.netD_B, 'D_B', label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDSI841_zPWi"
      },
      "source": [
        "def create_model(opt):\n",
        "    model = None\n",
        "    print(opt.model)\n",
        "    if opt.model == 'cycle_gan':\n",
        "        assert(opt.dataset_mode == 'unaligned')\n",
        "        model = CycleGANModel()\n",
        "    else:\n",
        "        raise ValueError(\"Model [%s] not recognized.\" % opt.model)\n",
        "    model.initialize(opt)\n",
        "    print(\"model [%s] was created\" % (model.name()))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HJ80i93yY2J"
      },
      "source": [
        "# 3. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urkNjHnaGKU0"
      },
      "source": [
        "import time\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCDZt7o9_iYw"
      },
      "source": [
        "model = create_model(opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-rht9c-n_JU"
      },
      "source": [
        "total_steps = 0\n",
        "\n",
        "for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    iter_data_time = time.time()\n",
        "    epoch_iter = 0\n",
        "\n",
        "    for i, data in tqdm(enumerate(dataset)):\n",
        "        iter_start_time = time.time()\n",
        "        if total_steps % opt.print_freq == 0: t_data = iter_start_time - iter_data_time\n",
        "        total_steps += opt.batchSize\n",
        "        epoch_iter += opt.batchSize\n",
        "        model.set_input(data)\n",
        "        model.optimize_parameters()\n",
        "\n",
        "        if total_steps % opt.print_freq == 0:\n",
        "            errors = model.get_current_errors()\n",
        "            t = (time.time() - iter_start_time) / opt.batchSize\n",
        "\n",
        "        if total_steps % opt.save_latest_freq == 0:\n",
        "            print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
        "            model.save('latest')\n",
        "\n",
        "        iter_data_time = time.time()\n",
        "        \n",
        "    if epoch % opt.save_epoch_freq == 0:\n",
        "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))\n",
        "        model.save('latest')\n",
        "        model.save(epoch)\n",
        "\n",
        "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
        "          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
        "    model.update_learning_rate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4grbzi3vcKE"
      },
      "source": [
        "model.save('latest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtxavWLnybl1"
      },
      "source": [
        "# 4. Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAn7lVOjGHnU"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu8jUtTbGBGN"
      },
      "source": [
        "model.load('latest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxbIgswIn_Jd"
      },
      "source": [
        "def show_img(im, ax=None, figsize=None):\n",
        "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
        "    ax.imshow(im)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtEneOCPn_Jm"
      },
      "source": [
        "def get_one(data):\n",
        "    model.set_input(data)\n",
        "    model.test()\n",
        "    return list(model.get_current_visuals().values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPlnmvq8n_J2"
      },
      "source": [
        "test_ims = []\n",
        "for i,o in enumerate(dataset):\n",
        "    if i>10: break\n",
        "    test_ims.append(get_one(o))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44hKlac5n_J9"
      },
      "source": [
        "def show_grid(ims):\n",
        "    fig,axes = plt.subplots(2,3,figsize=(9,6))\n",
        "    for i,ax in enumerate(axes.flat): show_img(ims[i], ax);\n",
        "    fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klpmo83Zn_KD"
      },
      "source": [
        "for i in range(8): show_grid(test_ims[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Rs6OMsiHHJQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}